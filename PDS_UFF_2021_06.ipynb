{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![verao](imagens/verao_uff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Univerisdade Federal Fluminense - UFF\n",
    "## Programa de Pós-graduação em Engenharia de Biossistemas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Escola de Verão 2021\n",
    "### Professor: Jorge Zavaleta. <jorge.zavaleta@ppgi.ufrj.br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c3k-CaB96pFT"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5UKkd2j86Wiv"
   },
   "source": [
    "# Módulo 05 - Aplicações em Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Scikit-Learn** - Biblioteca de aprendizado de máquina. [Scikit-Learn](https://scikit-learn.org/stable/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  A **regressão linear** é uma equação para estimar a condicional (valor esperado) de uma variável **y**, dados os valores de algumas outras variáveis **x**. Isto é, a **análise de regressão** estuda a relação entre uma variável chamada a **variável dependente** (y) e outras variáveis chamadas **variáveis independentes** (x).\n",
    "\n",
    "> $y = ax+b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar o dataset\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn import cluster\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "# thema\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dados\n",
    "X_all, y_all = datasets.make_regression(n_samples=50,n_features=50, n_informative=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dados de treimamento\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_all, y_all, train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando a instancia de regressao linear\n",
    "model = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste de modelo\n",
    "model.fit(X_train, y_train)\n",
    "#LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1,normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a soma do erro quadratico SSE\n",
    "def sse(resid):\n",
    "    return np.sum(resid**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcula o erro de treinamento\n",
    "resid_train = y_train - model.predict(X_train)\n",
    "sse_train = sse(resid_train)\n",
    "sse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcula o SSE do test dataset\n",
    "resid_test = y_test - model.predict(X_test)\n",
    "sse_test = sse(resid_test)\n",
    "sse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dados de treinamento\n",
    "# Resultado muito grande --> valor não fez um bom trabalho\n",
    "model.score(X_train, y_train)  # escore do r-quadrado = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de coeficientes do modelo = r*r\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dados de teste\n",
    "# escore do dataset de teste\n",
    "model.score(X_test, y_test) # grande diferença entre os datasets de treinamento e teste --> indica\n",
    "                            # modelo \"superaquecido\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função de aproximacao grafica\n",
    "def plot_valor_residuals_e_coef(resid_train, resid_test, coeff):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "    axes[0].bar(np.arange(len(resid_train)), resid_train)\n",
    "    axes[0].set_xlabel(\"Número de amostra\")\n",
    "    axes[0].set_ylabel(\"Residual\")\n",
    "    axes[0].set_title(\"dado de treinamento\")\n",
    "    axes[1].bar(np.arange(len(resid_test)), resid_test)\n",
    "    axes[1].set_xlabel(\"Número de amostra\")\n",
    "    axes[1].set_ylabel(\"Residual\")\n",
    "    axes[1].set_title(\"Dados de teste\")\n",
    "    axes[2].bar(np.arange(len(coeff)), coeff)\n",
    "    axes[2].set_xlabel(\"Número de coeficiente\")\n",
    "    axes[2].set_ylabel(\"Coeficiente\")\n",
    "    fig.tight_layout()\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafico dos resultados\n",
    "fig, ax = plot_valor_residuals_e_coef(resid_train, resid_test, model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> O resíduo entre o modelo de regressão linear ordinário e os dados de treinamento (esquerda), o modelo e os dados de teste (meio) e os valores do coeficientes para os 50 recursos (direita).\n",
    "\n",
    "> Problema de Overfiting devido a  poucos exemplos. Solução adicionar mais amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 solucion: -> regressao regularizada -> modelos matemáticos\n",
    "model = linear_model.Ridge(alpha=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metodo de ajuste com os dados de treinamento\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular o modelo de predição para os datasets de treinamento e teste\n",
    "resid_train = y_train - model.predict(X_train)\n",
    "sse_train = sse(resid_train)\n",
    "print('Treinamento:',sse_train)\n",
    "#\n",
    "resid_test = y_test - model.predict(X_test)\n",
    "sse_test = sse(resid_test)\n",
    "print('Teste:',sse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Observamos que o SSE dos dados de treinamento não está mais próximo de zero, mas há uma ligeira diminuição no SSE para os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultados gráficos\n",
    "fig, ax = plot_valor_residuals_e_coef(resid_train, resid_test, model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> O resíduo entre o modelo de regressão regularizado de Ridge e\n",
    "os dados de treinamento (esquerda), o modelo e os dados de teste (meio) e os valores dos coeficientes para os 50 recursos (direita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outro método regularização = LASSO\n",
    "model = linear_model.Lasso(alpha=1.0)   # alpha = 1.0 arbitrario !!!!\n",
    "# ajuste\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajuste para o dataset de treinamento\n",
    "resid_train = y_train - model.predict(X_train)\n",
    "sse_train = sse(resid_train)\n",
    "print('Treinameto:',sse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajuste para o dataset de teste\n",
    "resid_test = y_test - model.predict(X_test)\n",
    "sse_test = sse(resid_test)\n",
    "print('Teste:',sse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notamos que enquanto o SSE dos dados de treinamento aumentou em comparação com a regressão comum, o SSE para os dados de teste diminuiu significativamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gráfico\n",
    "fig, ax = plot_valor_residuals_e_coef(resid_train, resid_test, model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> O resíduo entre o modelo de regressão regularizado LASSO e os dados de treinamento (esquerda), o modelo e os dados de teste (meio) e os valores do coeficientes para os 50 recursos (direita)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Observamos que na regressão LASSO, uma vez que calculada parece funcionar bem para o problema atual, e resolvemos repetidamente o mesmo problema usando valores diferentes para o parâmetro de força de regularização $\\alpha$ enquanto armazenamos os valores dos coeficientes e valores SSE em matrizes NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar novos valores\n",
    "alphas = np.logspace(-4, 2, 100)\n",
    "coeffs = np.zeros((len(alphas), X_train.shape[1]))\n",
    "sse_train = np.zeros_like(alphas)\n",
    "sse_test = np.zeros_like(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Em seguida, fazemos um loop pelos valores α e realizamos a regressão LASSO para cada valor:\n",
    "for n, alpha in enumerate(alphas):\n",
    "    # modelo\n",
    "    model = linear_model.Lasso(alpha=alpha, fit_intercept=False, tol=0.00001,\n",
    "          max_iter=100000, positive=True)\n",
    "    # ajuste\n",
    "    model.fit(X_train, y_train)\n",
    "    coeffs[n, :] = model.coef_\n",
    "    sse_train[n] = sse(y_train - model.predict(X_train))\n",
    "    sse_test[n] = sse(y_test - model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharex=True)\n",
    "#\n",
    "for n in range(coeffs.shape[1]):\n",
    "    axes[0].plot(np.log10(alphas), coeffs[:, n], color='k', lw=0.5)\n",
    "#  \n",
    "axes[1].semilogy(np.log10(alphas), sse_train, label=\"treinamento\")\n",
    "axes[1].semilogy(np.log10(alphas), sse_test, label=\"teste\")\n",
    "axes[1].legend(loc=0)\n",
    "#\n",
    "axes[0].set_xlabel(r\"${\\log_{10}}\\alpha$\", fontsize=18)\n",
    "axes[0].set_ylabel(r\"coeficientes\", fontsize=18)\n",
    "#\n",
    "axes[1].set_xlabel(r\"${\\log_{10}}\\alpha$\", fontsize=18)\n",
    "axes[1].set_ylabel(r\"sse\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustes usando o modelo\n",
    "model = linear_model.LassoCV()\n",
    "model.fit(X_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valor regularizado\n",
    "model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores\n",
    "esid_train = y_train - model.predict(X_train)\n",
    "sse_train = sse(resid_train)\n",
    "print('Treinamento:',sse_train)\n",
    "resid_test = y_test - model.predict(X_test)\n",
    "sse_test = sse(resid_test)\n",
    "print('Teste:',sse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafico\n",
    "fig, ax = plot_valor_residuals_e_coef(resid_train, resid_test, model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajuste\n",
    "model = linear_model.ElasticNetCV()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores\n",
    "print(model.alpha_)\n",
    "print(model.l1_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores\n",
    "resid_train = y_train - model.predict(X_train)\n",
    "sse_train = sse(resid_train)\n",
    "print('Treinamento:',sse_train)\n",
    "resid_test = y_test - model.predict(X_test)\n",
    "sse_test = sse(resid_test)\n",
    "print('Teste:',sse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafico\n",
    "fig, ax = plot_valor_residuals_e_coef(resid_train, resid_test, model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação - Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load o dataset\n",
    "iris = datasets.load_iris()\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizar nomes descritivos\n",
    "print(iris.target_names)\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizar dimensoes da matriz de dados\n",
    "print(iris.data.shape)\n",
    "print(iris.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split o dataset em dados de treiamento (70%) e teste(30%) e validacao\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(iris.data, iris.target,\n",
    "                                                                    train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clasificador a usar\n",
    "classifier = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treinamento para clasificar é feito por ajustes (fit)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicao dos dados = predic\n",
    "y_test_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> O módulo **sklearn.metrics** contém funções auxiliares para auxiliar na análise do desempenho e precisão dos classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizar o reporte das metricas\n",
    "report = metrics.classification_report(y_test, y_test_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matriz de confusão\n",
    "matriz_conf = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "print(matriz_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores unicos\n",
    "vu = np.bincount(y_test)\n",
    "print(vu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usar outros classifcadores: arvore de decisão\n",
    "classifier = tree.DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_test_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiza as metricas\n",
    "rep = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "print(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando outros classifcadores\n",
    "# vetor de treinamento\n",
    "train_size_vec = np.linspace(0.1, 0.9, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes de classifcadores arvore, vezinho mais proximo, RandomForest, calssifcador de suporte vetorial (SVC)\n",
    "classifiers = [tree.DecisionTreeClassifier, neighbors.KNeighborsClassifier, svm.SVC,\n",
    "               ensemble.RandomForestClassifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guaradar la diagonal da matriz de confusao\n",
    "cm_diags = np.zeros((3, len(train_size_vec), len(classifiers)),dtype=float)\n",
    "#print(cm_diags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split os dados\n",
    "for n, train_size in enumerate(train_size_vec):\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(iris.data, iris.target,\n",
    "                                                                        train_size=train_size)\n",
    "    for m, Classifier in enumerate(classifiers):\n",
    "        classifier = Classifier()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_test_p = classifier.predict(X_test)\n",
    "        cm_diags[:, n, m] = metrics.confusion_matrix(y_test,y_test_p).diagonal()\n",
    "        cm_diags[:, n, m] /= np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acuracia de clasificação = grafico\n",
    "fig, axes = plt.subplots(1, len(classifiers), figsize=(12, 3))\n",
    "#\n",
    "for m, Classifier in enumerate(classifiers):\n",
    "    axes[m].plot(train_size_vec, cm_diags[2, :, m], label=iris.target_names[2])\n",
    "    axes[m].plot(train_size_vec, cm_diags[1, :, m], label=iris.target_names[1])\n",
    "    axes[m].plot(train_size_vec, cm_diags[0, :, m], label=iris.target_names[0])\n",
    "    axes[m].set_title(type(Classifier()).__name__)\n",
    "    axes[m].set_ylim(0, 1.1)\n",
    "    axes[m].set_ylabel(\"Acurácia da clssificação\")\n",
    "    axes[m].set_xlabel(\"P.T.T\")\n",
    "    axes[m].legend(loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusterização - Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load os dados\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster usando k-means, especificar o numero de clusters\n",
    "n_clusters = 3\n",
    "clustering = cluster.KMeans(n_clusters=n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajuste\n",
    "clustering.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizar resultados usando metodo predict (fit_predict)\n",
    "y_pred = clustering.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparar valores\n",
    "print(y_pred[::8])\n",
    "print(y[::8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrumar os valores\n",
    "idx_0, idx_1, idx_2 = (np.where(y_pred == n) for n in range(3))\n",
    "y_pred[idx_0], y_pred[idx_1], y_pred[idx_2] = 2, 0, 1\n",
    "print(y_pred[idx_0])\n",
    "print(y_pred[idx_1])\n",
    "print(y_pred[idx_2])\n",
    "print(y_pred[::8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matriz confusão\n",
    "mc = metrics.confusion_matrix(y, y_pred)\n",
    "print(mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# grafico\n",
    "N = X.shape[1]\n",
    "#\n",
    "fig, axes = plt.subplots(N, N, figsize=(12, 12), sharex=True, sharey=True)\n",
    "colors = [\"coral\", \"blue\", \"green\"]\n",
    "markers = [\"^\", \"v\", \"o\"]\n",
    "for m in range(N):\n",
    "    for n in range(N):\n",
    "        for p in range(n_clusters):\n",
    "            mask = y_pred == p\n",
    "            axes[m, n].scatter(X[:, m][mask], X[:, n][mask], s=30, marker=markers[p], \n",
    "                               color=colors[p], alpha=0.25)\n",
    "        for idx in np.where(y != y_pred):\n",
    "            axes[m, n].scatter(X[idx, m], X[idx, n], s=30, marker=\"s\", edgecolor=\"red\",\n",
    "                               facecolor=(1,1,1,0))\n",
    "    axes[N-1, m].set_xlabel(iris.feature_names[m], fontsize=16)\n",
    "    axes[m, 0].set_ylabel(iris.feature_names[m], fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> O resultado do agrupamento das amostras do dataset íris na gigura acima mostra que o agrupamento faz um bom trabalho em reconhecimento de amostras que pertencem a diferentes grupos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Python para Data Science**. &copy; Jorge Zavaleta, 2021."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMTc9xyCWa/8HuQenhSUJ02",
   "collapsed_sections": [],
   "name": "Python_Data_Science_UFF_2020_M4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
